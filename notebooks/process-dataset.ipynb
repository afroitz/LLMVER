{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = '../data/train.jsonl'\n",
    "single_source_path = '../data/single-source-all.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_json(data_path, lines=True)\n",
    "df_verifiable = df[df['verifiable'] == 'VERIFIABLE']\n",
    "df_unverifiable = df[df['verifiable'] == 'NOT VERIFIABLE']\n",
    "n_verifiable = len(df_verifiable)\n",
    "n_unverifiable = len(df_unverifiable)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Given an evidence value in the format used in the FEVER dataset, return the set of evidence article names.\n",
    "'''\n",
    "def get_evidence_article_set(evidence):\n",
    "    evidence_article_set = set()\n",
    "    for evidence_alternative in evidence:\n",
    "        for evidence_part in evidence_alternative:\n",
    "            evidence_article_set.add(evidence_part[2])\n",
    "    return evidence_article_set\n",
    "\n",
    "'''\n",
    "Given an evidence value in the format used in the FEVER dataset, return the evidence article name if there is only one article. Else, return None.\n",
    "'''\n",
    "def get_single_evidence_article(evidence):\n",
    "    evidence_article_set = get_evidence_article_set(evidence)\n",
    "    if len(evidence_article_set) == 1:\n",
    "        return next(iter(evidence_article_set))\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add a column for the single evidence article name if there is only one, else None.\n",
    "df_verifiable['evidence_article'] = df_verifiable['evidence'].apply(get_single_evidence_article)\n",
    "\n",
    "# Filter out the rows where there is no single evidence article.\n",
    "df_verifiable_single = df_verifiable[df_verifiable['evidence_article'].notnull()]\n",
    "\n",
    "# Keep the ratio of verifiable to unverifiable the same:\n",
    "# Compute ratio of verifiable discarded, discard same ratio of unverifiable.\n",
    "n_verifiable_single = len(df_verifiable_single)\n",
    "reduction_factor = n_verifiable_single / n_verifiable\n",
    "reduced_unverifiable = df_unverifiable.sample(frac=reduction_factor, random_state=1)\n",
    "\n",
    "# Combine the verifiable and unverifiable dataframes.\n",
    "df_single_source = pd.concat([df_verifiable_single, reduced_unverifiable]).sample(frac=1, random_state=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Compress the evidence: Preserve structure but discard annotation ids and article names.\n",
    "'''\n",
    "def compress_evidence(evidence):\n",
    "    compressed_evidence = []\n",
    "    for evidence_alternative in evidence:\n",
    "        compressed_evidence_alternative = []\n",
    "        for evidence_part in evidence_alternative:\n",
    "            compressed_evidence_alternative.append(evidence_part[3])\n",
    "        compressed_evidence.append(compressed_evidence_alternative)\n",
    "    return compressed_evidence\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add a column for the compressed evidence.\n",
    "df_single_source['compressed_evidence'] = df_single_source['evidence'].apply(compress_evidence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write the single source data to a csv file.\n",
    "df_single_source.to_csv(single_source_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the single source data to a csv file.\n",
    "df_single_source.to_csv(single_source_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}